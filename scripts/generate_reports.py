#!/usr/bin/env python3
"""Report generation for neoRL-industrial-gym project metrics and analytics.

This script generates various types of reports including development summaries,
quality metrics, performance analytics, and stakeholder dashboards.
"""

import argparse
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
import subprocess


class ReportGenerator:
    """Generate comprehensive project reports."""
    
    def __init__(self, repo_path: Path, metrics_file: Optional[Path] = None):
        self.repo_path = repo_path
        self.metrics_file = metrics_file or repo_path / ".github" / "project-metrics.json"
        self.metrics_data = self._load_metrics()
        
    def _load_metrics(self) -> Dict[str, Any]:
        """Load metrics data from file."""
        try:
            with open(self.metrics_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"Warning: Metrics file not found: {self.metrics_file}")
            return {"project": {"name": "neoRL-industrial-gym"}, "metrics": {}}
    
    def generate_executive_summary(self) -> str:
        """Generate an executive summary report."""
        report = []
        project_name = self.metrics_data.get("project", {}).get("name", "neoRL-industrial-gym")
        
        report.append(f"# Executive Summary - {project_name}")
        report.append(f"**Report Date:** {datetime.now().strftime('%Y-%m-%d')}")
        report.append("")
        
        # Project overview
        report.append("## Project Overview")
        description = self.metrics_data.get("project", {}).get("description", "Industrial-grade Offline RL benchmark & library")
        report.append(f"{description}")
        report.append("")
        
        # Key metrics
        report.append("## Key Performance Indicators")
        metrics = self.metrics_data.get("metrics", {})
        
        # Development activity
        dev_metrics = metrics.get("development", {})
        commits = dev_metrics.get("commits", {})
        report.append(f"- **Total Commits:** {commits.get('total', 0):,}")
        report.append(f"- **Active Contributors:** {len(commits.get('contributors', []))}")
        report.append(f"- **Recent Activity:** {commits.get('last_month', 0)} commits this month")
        
        # Quality metrics
        quality_metrics = metrics.get("quality", {})
        coverage = quality_metrics.get("code_coverage", {})
        test_metrics = quality_metrics.get("test_metrics", {})
        report.append(f"- **Code Coverage:** {coverage.get('current', 0)}%")
        report.append(f"- **Total Tests:** {test_metrics.get('total_tests', 0):,}")
        
        # Community engagement
        community_metrics = metrics.get("community", {})
        engagement = community_metrics.get("engagement", {})
        report.append(f"- **GitHub Stars:** {engagement.get('github_stars', 0):,}")
        report.append(f"- **GitHub Forks:** {engagement.get('github_forks', 0):,}")
        
        report.append("")
        
        # Industrial metrics
        industrial_metrics = metrics.get("industrial_specific", {})
        if industrial_metrics:
            report.append("## Industrial Safety & Compliance")
            safety_metrics = industrial_metrics.get("safety_metrics", {})\n            env_coverage = industrial_metrics.get("environment_coverage", {})\n            report.append(f\"- **Safety Tests:** {safety_metrics.get('safety_tests_passing', 0)}\")\n            report.append(f\"- **Environments Covered:** {env_coverage.get('tested_environments', 0)}/{env_coverage.get('total_environments', 7)}\")\n            report.append(\"\")\n        \n        # Goals and progress\n        goals = self.metrics_data.get(\"goals\", {})\n        if goals:\n            report.append(\"## Progress Toward Goals\")\n            current_quarter = f\"{datetime.now().year}_q{(datetime.now().month - 1) // 3 + 1}\"\n            if current_quarter in goals:\n                quarter_goals = goals[current_quarter]\n                actual_stars = engagement.get('github_stars', 0)\n                target_stars = quarter_goals.get('github_stars', 0)\n                if target_stars > 0:\n                    progress = min(100, (actual_stars / target_stars) * 100)\n                    report.append(f\"- **GitHub Stars Progress:** {actual_stars:,}/{target_stars:,} ({progress:.1f}%)\")\n                \n                actual_contributors = len(commits.get('contributors', []))\n                target_contributors = quarter_goals.get('contributors', 0)\n                if target_contributors > 0:\n                    progress = min(100, (actual_contributors / target_contributors) * 100)\n                    report.append(f\"- **Contributors Progress:** {actual_contributors}/{target_contributors} ({progress:.1f}%)\")\n            report.append(\"\")\n        \n        # Risk assessment\n        report.append(\"## Risk Assessment\")\n        security_metrics = quality_metrics.get(\"security\", {})\n        vulnerabilities = security_metrics.get(\"vulnerabilities\", {})\n        critical_vulns = vulnerabilities.get(\"critical\", 0)\n        high_vulns = vulnerabilities.get(\"high\", 0)\n        \n        if critical_vulns > 0:\n            report.append(f\"- üî¥ **HIGH RISK:** {critical_vulns} critical security vulnerabilities\")\n        elif high_vulns > 0:\n            report.append(f\"- üü° **MEDIUM RISK:** {high_vulns} high-severity security vulnerabilities\")\n        else:\n            report.append(\"- üü¢ **LOW RISK:** No critical security vulnerabilities detected\")\n        \n        # Code coverage risk\n        current_coverage = coverage.get('current', 0)\n        target_coverage = self.metrics_data.get(\"thresholds\", {}).get(\"quality\", {}).get(\"code_coverage_minimum\", 80)\n        if current_coverage < target_coverage:\n            report.append(f\"- üü° **QUALITY RISK:** Code coverage ({current_coverage}%) below target ({target_coverage}%)\")\n        else:\n            report.append(f\"- üü¢ **QUALITY:** Code coverage meets target ({current_coverage}% >= {target_coverage}%)\")\n        \n        report.append(\"\")\n        \n        # Recommendations\n        report.append(\"## Recommendations\")\n        recommendations = []\n        \n        if critical_vulns > 0:\n            recommendations.append(\"Address critical security vulnerabilities immediately\")\n        if current_coverage < target_coverage:\n            recommendations.append(f\"Increase test coverage to meet {target_coverage}% target\")\n        if commits.get('last_week', 0) == 0:\n            recommendations.append(\"Increase development activity - no commits in the last week\")\n        if len(commits.get('contributors', [])) < 5:\n            recommendations.append(\"Expand contributor base for better project sustainability\")\n        \n        if not recommendations:\n            recommendations.append(\"Continue current development practices\")\n            recommendations.append(\"Monitor metrics regularly for early issue detection\")\n        \n        for i, rec in enumerate(recommendations, 1):\n            report.append(f\"{i}. {rec}\")\n        \n        report.append(\"\")\n        report.append(\"---\")\n        report.append(f\"*Report generated automatically on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\")\n        \n        return \"\\n\".join(report)\n    \n    def generate_technical_report(self) -> str:\n        \"\"\"Generate a detailed technical report.\"\"\"\n        report = []\n        project_name = self.metrics_data.get(\"project\", {}).get(\"name\", \"neoRL-industrial-gym\")\n        \n        report.append(f\"# Technical Report - {project_name}\")\n        report.append(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        report.append(\"\")\n        \n        metrics = self.metrics_data.get(\"metrics\", {})\n        \n        # Development metrics\n        dev_metrics = metrics.get(\"development\", {})\n        if dev_metrics:\n            report.append(\"## Development Activity\")\n            \n            commits = dev_metrics.get(\"commits\", {})\n            report.append(f\"- Total commits: {commits.get('total', 0):,}\")\n            report.append(f\"- Commits last week: {commits.get('last_week', 0)}\")\n            report.append(f\"- Commits last month: {commits.get('last_month', 0)}\")\n            report.append(f\"- Commits last quarter: {commits.get('last_quarter', 0)}\")\n            \n            contributors = commits.get('contributors', [])\n            if contributors:\n                report.append(f\"- Total contributors: {len(contributors)}\")\n                report.append(\"\")\n                report.append(\"### Top Contributors\")\n                for i, contributor in enumerate(contributors[:5], 1):\n                    name = contributor.get('name', 'Unknown')\n                    commit_count = contributor.get('commits', 0)\n                    report.append(f\"{i}. {name}: {commit_count} commits\")\n            \n            report.append(\"\")\n            \n            # Pull requests and issues\n            prs = dev_metrics.get(\"pull_requests\", {})\n            if prs:\n                report.append(\"### Pull Requests\")\n                report.append(f\"- Total: {prs.get('total', 0)}\")\n                report.append(f\"- Open: {prs.get('open', 0)}\")\n                report.append(f\"- Merged: {prs.get('merged', 0)}\")\n                report.append(f\"- Average time to merge: {prs.get('average_time_to_merge', 'N/A')}\")\n                report.append(\"\")\n            \n            issues = dev_metrics.get(\"issues\", {})\n            if issues:\n                report.append(\"### Issues\")\n                report.append(f\"- Total: {issues.get('total', 0)}\")\n                report.append(f\"- Open: {issues.get('open', 0)}\")\n                report.append(f\"- Closed: {issues.get('closed', 0)}\")\n                report.append(f\"- Bugs: {issues.get('bugs', 0)}\")\n                report.append(f\"- Enhancements: {issues.get('enhancements', 0)}\")\n                report.append(\"\")\n        \n        # Quality metrics\n        quality_metrics = metrics.get(\"quality\", {})\n        if quality_metrics:\n            report.append(\"## Code Quality\")\n            \n            # Coverage\n            coverage = quality_metrics.get(\"code_coverage\", {})\n            if coverage:\n                current = coverage.get('current', 0)\n                target = coverage.get('target', 85)\n                trend = coverage.get('trend', 'unknown')\n                report.append(f\"- Code coverage: {current}% (target: {target}%, trend: {trend})\")\n                \n                if current < target:\n                    report.append(f\"  ‚ö†Ô∏è  Below target by {target - current}%\")\n                else:\n                    report.append(f\"  ‚úÖ Meets target\")\n            \n            # Test metrics\n            test_metrics = quality_metrics.get(\"test_metrics\", {})\n            if test_metrics:\n                total = test_metrics.get('total_tests', 0)\n                passing = test_metrics.get('passing_tests', 0)\n                failing = test_metrics.get('failing_tests', 0)\n                flaky = test_metrics.get('flaky_tests', 0)\n                \n                report.append(f\"- Total tests: {total:,}\")\n                report.append(f\"- Passing tests: {passing:,}\")\n                report.append(f\"- Failing tests: {failing}\")\n                report.append(f\"- Flaky tests: {flaky}\")\n                \n                if total > 0:\n                    pass_rate = (passing / total) * 100\n                    report.append(f\"- Pass rate: {pass_rate:.1f}%\")\n            \n            # Code quality scores\n            code_quality = quality_metrics.get(\"code_quality\", {})\n            if code_quality:\n                report.append(f\"- Linting score: {code_quality.get('linting_score', 0)}\")\n                report.append(f\"- Complexity score: {code_quality.get('complexity_score', 0)}\")\n                report.append(f\"- Duplication: {code_quality.get('duplication_percentage', 0)}%\")\n            \n            # Security\n            security = quality_metrics.get(\"security\", {})\n            if security:\n                report.append(\"\")\n                report.append(\"### Security Metrics\")\n                vulnerabilities = security.get('vulnerabilities', {})\n                report.append(f\"- Critical vulnerabilities: {vulnerabilities.get('critical', 0)}\")\n                report.append(f\"- High vulnerabilities: {vulnerabilities.get('high', 0)}\")\n                report.append(f\"- Medium vulnerabilities: {vulnerabilities.get('medium', 0)}\")\n                report.append(f\"- Low vulnerabilities: {vulnerabilities.get('low', 0)}\")\n                report.append(f\"- Security score: {security.get('security_score', 0)}/100\")\n            \n            report.append(\"\")\n        \n        # Performance metrics\n        performance_metrics = metrics.get(\"performance\", {})\n        if performance_metrics:\n            report.append(\"## Performance Metrics\")\n            \n            build_times = performance_metrics.get(\"build_times\", {})\n            if build_times:\n                report.append(f\"- Average build time: {build_times.get('average', 'N/A')}\")\n                report.append(f\"- Fastest build: {build_times.get('fastest', 'N/A')}\")\n                report.append(f\"- Slowest build: {build_times.get('slowest', 'N/A')}\")\n                report.append(f\"- Build time trend: {build_times.get('trend', 'unknown')}\")\n            \n            deployment = performance_metrics.get(\"deployment_frequency\", {})\n            if deployment:\n                report.append(f\"- Deployments per week: {deployment.get('per_week', 0)}\")\n                report.append(f\"- Deployments per month: {deployment.get('per_month', 0)}\")\n            \n            lead_time = performance_metrics.get(\"lead_time\", {})\n            if lead_time:\n                report.append(f\"- Average lead time: {lead_time.get('average', 'N/A')}\")\n                report.append(f\"- Median lead time: {lead_time.get('median', 'N/A')}\")\n            \n            mttr = performance_metrics.get(\"mean_time_to_recovery\", {})\n            if mttr:\n                report.append(f\"- Mean time to recovery: {mttr.get('average', 'N/A')}\")\n                report.append(f\"- Incidents handled: {mttr.get('incidents', 0)}\")\n            \n            report.append(\"\")\n        \n        # Industrial-specific metrics\n        industrial_metrics = metrics.get(\"industrial_specific\", {})\n        if industrial_metrics:\n            report.append(\"## Industrial & Safety Metrics\")\n            \n            safety = industrial_metrics.get(\"safety_metrics\", {})\n            if safety:\n                report.append(f\"- Safety tests passing: {safety.get('safety_tests_passing', 0)}\")\n                report.append(f\"- Safety constraint coverage: {safety.get('safety_constraint_coverage', 0)}%\")\n                report.append(f\"- Emergency shutdown tests: {safety.get('emergency_shutdown_tests', 0)}\")\n                if safety.get('last_safety_audit'):\n                    report.append(f\"- Last safety audit: {safety['last_safety_audit']}\")\n            \n            env_coverage = industrial_metrics.get(\"environment_coverage\", {})\n            if env_coverage:\n                total_envs = env_coverage.get('total_environments', 7)\n                tested_envs = env_coverage.get('tested_environments', 0)\n                coverage_pct = (tested_envs / total_envs * 100) if total_envs > 0 else 0\n                report.append(f\"- Environment coverage: {tested_envs}/{total_envs} ({coverage_pct:.1f}%)\")\n                report.append(f\"- Benchmark coverage: {env_coverage.get('benchmark_coverage', 0)}%\")\n            \n            algo_performance = industrial_metrics.get(\"algorithm_performance\", {})\n            if algo_performance:\n                report.append(f\"- Algorithms implemented: {algo_performance.get('algorithms_implemented', 0)}\")\n                report.append(f\"- Benchmarked algorithms: {algo_performance.get('benchmarked_algorithms', 0)}\")\n                report.append(f\"- Performance regressions: {algo_performance.get('performance_regressions', 0)}\")\n            \n            validation = industrial_metrics.get(\"industrial_validation\", {})\n            if validation:\n                report.append(f\"- Real-world datasets: {validation.get('real_world_datasets', 0)}\")\n                report.append(f\"- Factory validations: {validation.get('factory_validations', 0)}\")\n                report.append(f\"- Compliance checks: {validation.get('compliance_checks', 0)}\")\n                report.append(f\"- Certification status: {validation.get('certification_status', 'Unknown')}\")\n            \n            report.append(\"\")\n        \n        # Thresholds and compliance\n        thresholds = self.metrics_data.get(\"thresholds\", {})\n        if thresholds:\n            report.append(\"## Threshold Compliance\")\n            \n            quality_thresholds = thresholds.get(\"quality\", {})\n            performance_thresholds = thresholds.get(\"performance\", {})\n            safety_thresholds = thresholds.get(\"safety\", {})\n            \n            # Check compliance\n            compliance_issues = []\n            \n            # Quality compliance\n            if quality_thresholds:\n                min_coverage = quality_thresholds.get('code_coverage_minimum', 80)\n                current_coverage = quality_metrics.get('code_coverage', {}).get('current', 0)\n                if current_coverage < min_coverage:\n                    compliance_issues.append(f\"Code coverage ({current_coverage}%) below minimum ({min_coverage}%)\")\n                \n                min_security = quality_thresholds.get('security_score_minimum', 95)\n                current_security = quality_metrics.get('security', {}).get('security_score', 100)\n                if current_security < min_security:\n                    compliance_issues.append(f\"Security score ({current_security}) below minimum ({min_security})\")\n            \n            if compliance_issues:\n                report.append(\"‚ùå **Compliance Issues:**\")\n                for issue in compliance_issues:\n                    report.append(f\"- {issue}\")\n            else:\n                report.append(\"‚úÖ **All thresholds met**\")\n            \n            report.append(\"\")\n        \n        report.append(\"---\")\n        report.append(f\"*Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\")\n        \n        return \"\\n\".join(report)\n    \n    def generate_csv_export(self) -> str:\n        \"\"\"Generate a CSV export of key metrics.\"\"\"\n        lines = []\n        lines.append(\"Metric,Value,Category,Timestamp\")\n        \n        timestamp = datetime.now().isoformat()\n        metrics = self.metrics_data.get(\"metrics\", {})\n        \n        # Development metrics\n        dev_metrics = metrics.get(\"development\", {})\n        commits = dev_metrics.get(\"commits\", {})\n        lines.append(f\"Total Commits,{commits.get('total', 0)},Development,{timestamp}\")\n        lines.append(f\"Commits Last Week,{commits.get('last_week', 0)},Development,{timestamp}\")\n        lines.append(f\"Commits Last Month,{commits.get('last_month', 0)},Development,{timestamp}\")\n        lines.append(f\"Total Contributors,{len(commits.get('contributors', []))},Development,{timestamp}\")\n        \n        # Quality metrics\n        quality_metrics = metrics.get(\"quality\", {})\n        coverage = quality_metrics.get(\"code_coverage\", {})\n        lines.append(f\"Code Coverage,{coverage.get('current', 0)},Quality,{timestamp}\")\n        \n        test_metrics = quality_metrics.get(\"test_metrics\", {})\n        lines.append(f\"Total Tests,{test_metrics.get('total_tests', 0)},Quality,{timestamp}\")\n        lines.append(f\"Passing Tests,{test_metrics.get('passing_tests', 0)},Quality,{timestamp}\")\n        \n        security = quality_metrics.get(\"security\", {})\n        vulnerabilities = security.get('vulnerabilities', {})\n        lines.append(f\"Critical Vulnerabilities,{vulnerabilities.get('critical', 0)},Security,{timestamp}\")\n        lines.append(f\"High Vulnerabilities,{vulnerabilities.get('high', 0)},Security,{timestamp}\")\n        \n        # Community metrics\n        community_metrics = metrics.get(\"community\", {})\n        engagement = community_metrics.get(\"engagement\", {})\n        lines.append(f\"GitHub Stars,{engagement.get('github_stars', 0)},Community,{timestamp}\")\n        lines.append(f\"GitHub Forks,{engagement.get('github_forks', 0)},Community,{timestamp}\")\n        \n        # Industrial metrics\n        industrial_metrics = metrics.get(\"industrial_specific\", {})\n        safety_metrics = industrial_metrics.get(\"safety_metrics\", {})\n        lines.append(f\"Safety Tests,{safety_metrics.get('safety_tests_passing', 0)},Safety,{timestamp}\")\n        \n        env_coverage = industrial_metrics.get(\"environment_coverage\", {})\n        tested_envs = env_coverage.get('tested_environments', 0)\n        total_envs = env_coverage.get('total_environments', 7)\n        coverage_pct = (tested_envs / total_envs * 100) if total_envs > 0 else 0\n        lines.append(f\"Environment Coverage,{coverage_pct:.1f},Industrial,{timestamp}\")\n        \n        return \"\\n\".join(lines)\n    \n    def generate_dashboard_json(self) -> str:\n        \"\"\"Generate JSON data for dashboard consumption.\"\"\"\n        dashboard_data = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"project\": self.metrics_data.get(\"project\", {}),\n            \"summary\": {},\n            \"charts\": {},\n            \"alerts\": []\n        }\n        \n        metrics = self.metrics_data.get(\"metrics\", {})\n        \n        # Summary KPIs\n        dev_metrics = metrics.get(\"development\", {})\n        commits = dev_metrics.get(\"commits\", {})\n        quality_metrics = metrics.get(\"quality\", {})\n        community_metrics = metrics.get(\"community\", {})\n        \n        dashboard_data[\"summary\"] = {\n            \"total_commits\": commits.get('total', 0),\n            \"active_contributors\": len(commits.get('contributors', [])),\n            \"code_coverage\": quality_metrics.get('code_coverage', {}).get('current', 0),\n            \"github_stars\": community_metrics.get('engagement', {}).get('github_stars', 0),\n            \"security_score\": quality_metrics.get('security', {}).get('security_score', 100)\n        }\n        \n        # Chart data\n        dashboard_data[\"charts\"] = {\n            \"commit_activity\": {\n                \"labels\": [\"Last Week\", \"Last Month\", \"Last Quarter\"],\n                \"data\": [\n                    commits.get('last_week', 0),\n                    commits.get('last_month', 0),\n                    commits.get('last_quarter', 0)\n                ]\n            },\n            \"quality_metrics\": {\n                \"coverage\": quality_metrics.get('code_coverage', {}).get('current', 0),\n                \"tests\": quality_metrics.get('test_metrics', {}).get('total_tests', 0),\n                \"security\": quality_metrics.get('security', {}).get('security_score', 100)\n            }\n        }\n        \n        # Alerts\n        thresholds = self.metrics_data.get(\"thresholds\", {})\n        quality_thresholds = thresholds.get(\"quality\", {})\n        \n        # Coverage alert\n        current_coverage = quality_metrics.get('code_coverage', {}).get('current', 0)\n        min_coverage = quality_thresholds.get('code_coverage_minimum', 80)\n        if current_coverage < min_coverage:\n            dashboard_data[\"alerts\"].append({\n                \"type\": \"warning\",\n                \"message\": f\"Code coverage ({current_coverage}%) below target ({min_coverage}%)\",\n                \"category\": \"quality\"\n            })\n        \n        # Security alerts\n        vulnerabilities = quality_metrics.get('security', {}).get('vulnerabilities', {})\n        critical_vulns = vulnerabilities.get('critical', 0)\n        if critical_vulns > 0:\n            dashboard_data[\"alerts\"].append({\n                \"type\": \"error\",\n                \"message\": f\"{critical_vulns} critical security vulnerabilities detected\",\n                \"category\": \"security\"\n            })\n        \n        return json.dumps(dashboard_data, indent=2)\n\n\ndef main():\n    \"\"\"Main function for report generation.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Generate reports for neoRL-industrial-gym\")\n    parser.add_argument(\"--repo-path\", type=Path, default=Path.cwd(), help=\"Repository path\")\n    parser.add_argument(\"--metrics-file\", type=Path, help=\"Metrics data file\")\n    parser.add_argument(\"--report-type\", choices=[\"executive\", \"technical\", \"csv\", \"dashboard\"], \n                       default=\"executive\", help=\"Type of report to generate\")\n    parser.add_argument(\"--output\", type=Path, help=\"Output file for the report\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Verbose output\")\n    \n    args = parser.parse_args()\n    \n    # Initialize report generator\n    generator = ReportGenerator(args.repo_path, args.metrics_file)\n    \n    if args.verbose:\n        print(f\"üìä Generating {args.report_type} report...\")\n        print(f\"üìÅ Repository: {args.repo_path}\")\n        print(f\"üìÑ Metrics file: {generator.metrics_file}\")\n    \n    # Generate report based on type\n    if args.report_type == \"executive\":\n        report = generator.generate_executive_summary()\n    elif args.report_type == \"technical\":\n        report = generator.generate_technical_report()\n    elif args.report_type == \"csv\":\n        report = generator.generate_csv_export()\n    elif args.report_type == \"dashboard\":\n        report = generator.generate_dashboard_json()\n    else:\n        print(f\"Error: Unknown report type: {args.report_type}\")\n        sys.exit(1)\n    \n    # Output report\n    if args.output:\n        with open(args.output, 'w') as f:\n            f.write(report)\n        if args.verbose:\n            print(f\"‚úÖ Report saved to: {args.output}\")\n    else:\n        print(report)\n    \n    if args.verbose:\n        print(\"üìã Report generation completed successfully!\")\n\n\nif __name__ == \"__main__\":\n    main()"